\section{Discussion}

The sharp increase in average cross-entropy for the community and top users in Period 10 is anomalous in several aspects. This period includes the weeks of the election, but it doesn't have the highest number of posts. But it does have the highest number of unique posters in our time-frame, a sharp increase from the previous period, even if the successive period, with its lower cross-entropy, doesn't see a sharp fall in posters (see Figure \ref{fig:sub_stats}).

Breitbart's position on the issue dimensions is an interesting case to examine. Given the consistency in the loadings of other outlets on these  dimensions, one would expect Breitbart to have a relatively stable position across these windows. Instead, what we see is that Breitbart's position shifts, closer at times to the conservative National Review and on the opposite end at others. One explanation for this could be that that constructed dimensions are not stable and don't encode the information we think it does. Testing and tuning these dimensions for greater reliability would be essential in making these results generalizable. An alternate hypothesis is that the nature of Breitbart's newsroom -- digital, highly partisan, more finely attuned to and reliant upon online communities for amplification -- make it fundamentally different from the more traditional outlets we compare against. Adding outlets like Vox Media, Huffington Post, or Buzzfeed could provide a third set of comparisons, among internet-first news outlets. But one could also examine how the language in Breitbart's articles linked on the subreddit align with the language in the subreddit. 

This paper examines how the linguisitic characteristics of a politically-engaged community changes with time, with an examination of how key phrases shift in accordance to events. We've been able to examine the relationship between a user's status and the language of the community, with our results replicating some of the findings in Danescu-Niculescu-Mizil et al.'s work. \citep{danescu-niculescu-mizil_no_2013}. Further work on this should focus on expanding beyond the $n$-gram model to quantify community language. Word Embedding methods which are able to better capture context could be used to identify more fine-tuned linguistic norms. Formalizing user status with centrality measures and sub-community network detection could help us tease out amplification channels within this community to examine in-group competition.      